# Sign-Language

### ğŸ“„ `README.md`


# ğŸ§  Sign Language Detection and Representation System

This project is a real-time sign language recognition system that detects hand gestures via webcam and represents them as corresponding text. Built using Python, Flask, OpenCV, MediaPipe, and TensorFlow, the system helps bridge communication gaps for the hearing-impaired community.

## ğŸš€ Features

- âœ‹ Real-time hand gesture detection using webcam
- ğŸ§  Machine Learning model for sign classification
- ğŸ¯ Custom dataset creation using Python scripts
- ğŸ“· Uses MediaPipe and OpenCV for hand tracking
- ğŸŒ Web-based interface powered by Flask
- ğŸ–¼ï¸ Sign representation through text/image

---

## ğŸ› ï¸ Technologies Used

| Technology     | Purpose                         |
|----------------|----------------------------------|
| Python         | Core programming language       |
| Flask          | Web framework for backend        |
| OpenCV         | Image capturing and processing   |
| MediaPipe      | Hand landmark detection          |
| TensorFlow     | Training and prediction model    |
| HTML/CSS       | Frontend interface               |

---

## ğŸ“¦ Project Structure

```

sign-language-project/
â”‚
â”œâ”€â”€ app.py                      # Flask server
â”œâ”€â”€ static/
â”‚   â””â”€â”€ css/
â”‚   â””â”€â”€ â””â”€â”€ home.css
â”‚   â””â”€â”€ js/
â”‚   â””â”€â”€ â””â”€â”€ signin.js
â”‚   â””â”€â”€ signs/
â”‚   â””â”€â”€ â””â”€â”€ 0.jpg
|   â””â”€â”€ â””â”€â”€ 1.jpg              
â”œâ”€â”€ templates/
â”œâ”€â”€ â””â”€â”€ images/
â”‚   â””â”€â”€ â””â”€â”€ signdetect.jpg
â”‚   â””â”€â”€ home.html              # Frontend page
â”‚   â””â”€â”€ login.html
â”‚   â””â”€â”€ sign_detection.html
â”‚   â””â”€â”€ sign_representation.html
â”‚   â””â”€â”€ sign_up.html   
â”œâ”€â”€ create_dataset.py          # Script to create dataset
â”œâ”€â”€ collect_images.py
â”œâ”€â”€ inference_classifier.py
â”œâ”€â”€ model.p
â”œâ”€â”€ train_classifier.py        # Saved ML model
â””â”€â”€ README.md                   # Project documentation

````

---

## ğŸ“· Dataset Creation

- Run `create_dataset.py` to collect gesture images.
- The script captures frames from the webcam and saves them labeled by gesture name.
- Ensure good lighting and background while collecting data.

```bash
python create_dataset.py
````

---

## ğŸ§  Model Training

* Use `model_training.py` to train a CNN model using TensorFlow on the collected dataset.

```bash
python train_classifier.py
```

---

## ğŸŒ Running the Flask App

1. Start the Flask server:

   ```bash
   python app.py
   ```

2. Open your browser and go to `http://127.0.0.1:5000/`

3. Start showing hand gestures in front of your webcam.

---

## ğŸ“Š Future Improvements

* Add support for more gestures and complete words
* Integrate text-to-speech (TTS) for audio output
* Train model with ASL or ISL official datasets
* Add sign-to-sign communication for two-way interaction

---

## ğŸ¤ Contributing

Pull requests and contributions are welcome! If you have suggestions or improvements, feel free to fork the repo and open a PR.

---

## ğŸ“œ License

This project is open-source and available under the MIT License.

---

## ğŸ‘¤ Author


Email: \[[mounikaundela999@example.com](mailto:your.email@example.com)]
GitHub: \[https://github.com/Mounika9929/Sign-Language]

---
